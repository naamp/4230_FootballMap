{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selenium Scraping\n",
    "\n",
    "Scraping mit Python und Selenium\n",
    "Installiere die Bibliotheken für Anaconda Environment:\n",
    "\n",
    "```bash\n",
    "conda install -c conda-forge selenium\n",
    "```\n",
    "\n",
    "https://sites.google.com/chromium.org/driver/downloads\n",
    "https://stackoverflow.com/questions/76461596/unable-to-use-selenium-webdriver-getting-two-exceptions\n",
    "https://scrapeops.io/selenium-web-scraping-playbook/python-selenium-error-chromedriver-executable-path/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "\n",
    "# Check Version of Selenium\n",
    "print(\"Selenium Version: \" + str(webdriver.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "service = Service()\n",
    "options = webdriver.ChromeOptions()\n",
    "# This will automatically install Chromedriver\n",
    "driver = webdriver.Chrome(service=service, options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spieler_nr = [\n",
    "    900486, 863745, 191486, 659352, 806015, 654234, 925199, 847283, 548031, 922788, 937941, 376460,\n",
    "    405568, 700479, 264956, 195906, 583011, 448169, 135471, 655629, 199453, 579459, 345780, 390168, 860052, 620806,\n",
    "    357860, 927734, 422401, 514380, 887792, 673513, 286292, 1015812, 535761, 461461, 256085, 192637, 102409, 502342,\n",
    "    698026, 801754, 86484, 604616, 194638, 344610, 340427, 274439, 86030, 237660, 992432, 318707, 165435, 111428,\n",
    "    830057, 160736, 121528, 463744, 41767, 272640, 237986, 550862, 361567, 667870, 183312, 618408, 395512, 583058,\n",
    "    68655, 534360, 876400, 812654, 433254, 424051, 364861, 625816, 342227, 847262, 583038, 811022, 68030, 539798,\n",
    "    452560, 392743, 539797, 135344, 388664, 146710, 678843, 583026, 290040, 608172, 382774, 192638, 622023, 192166,\n",
    "    146164, 434084, 183446, 582019, 748358, 371554, 678847, 503327, 707759, 167342, 575610, 333161, 78868, 170344,\n",
    "    628380, 340065, 450417, 578292, 272638, 624910, 88404, 358507, 816702, 353886, 539808, 810969, 322309, 237843,\n",
    "    324796, 1026014, 439351, 346898, 237669, 897461, 75816, 880517, 353567, 290016, 291110, 938009, 805487, 254285,\n",
    "    196791, 707548, 261935333450, 543379, 639580, 477681, 449597, 284035, 582353, 410617, 166679, 410636, 948736, 390179,\n",
    "    499330, 179638, 507490, 336857, 183447, 376675, 507496, 500762, 247459, 684604, 463620, 606389, 276998, 943795,\n",
    "    165532, 178277,\n",
    "    203926, 422051, 464190, 602443, 66109, 265208, 45685, 649087, 659313, 426213, 691356, 698560, 338864, 539809,\n",
    "    180090, 282724, 507477, 150963, 507412, 289404, 531461, 1111660, 451483, 754158, 862744, 819306, 45832, 496239,\n",
    "    91410, 499319, 61150, 405389, 448883, 488298, 293742, 620764, 461595, 500748, 183448, 333815, 704412, 807941,\n",
    "    66005, 253574, 396361, 659353, 500771, 65290, 629005, 413461, 406614, 379980, 255729, 861246, 690246, 539801,\n",
    "    153107, 408438, 318507, 284695, 691301, 312051, 534375, 110475, 539807, 180442, 465565, 126514, 69899, 521446,\n",
    "    183311, 452238, 371088, 376453, 401526, 490581, 614259, 507466, 373301, 507425, 343064, 192676, 682032, 510263,\n",
    "    471140, 310361, 514623, 607914, 718201, 573974, 346903, 823521, 203770, 169372, 1010818, 417895, 402055, 460648,\n",
    "    519619, 254972, 521442, 357858, 919173, 517372, 60539, 460347, 410616, 170535, 192714, 507339, 804664, 810096,\n",
    "    284280, 421789, 511801, 354136, 321082, 418658, 443425, 500763, 123147, 357862, 269526, 237677, 291896, 583054,\n",
    "    86676, 294801, 237679, 410870, 342063, 183313, 499196, 147040, 507472, 147037, 59246, 539811, 421823, 500758,\n",
    "    227967, 388220, 563098, 346900, 463666, 192655, 111430\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import time\n",
    "\n",
    "scroll_js = \"window.scrollTo(0, document.body.scrollHeight);\"\n",
    "\n",
    "# Öffne die CSV-Datei außerhalb der Schleife\n",
    "with open('transfer_data.csv', 'w', newline='', encoding='utf-8') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['player_nr', 'Saison', 'Datum', 'Abgebender Verein', 'Aufnehmender Verein', 'MW', 'Ablöse'])\n",
    "\n",
    "    for spieler_id in spieler_nr:\n",
    "        url = f\"https://www.transfermarkt.ch/spielername/transfers/spieler/{spieler_id}\"\n",
    "        driver.get(url)\n",
    "\n",
    "        # Zustimmung für Cookies\n",
    "        try:\n",
    "            wait = WebDriverWait(driver, 20)\n",
    "            wait.until(EC.frame_to_be_available_and_switch_to_it((By.XPATH, \"//div[@id='sp_message_container_953386']/iframe\")))\n",
    "            driver.find_element(By.XPATH, \"//button[contains(@aria-label, 'Zustimmen & weiter')]\").click()\n",
    "        except TimeoutException:\n",
    "            pass\n",
    "\n",
    "        # Scrollen\n",
    "        for _ in range(3):  # Dreimaliges Scrollen\n",
    "            driver.execute_script(scroll_js)\n",
    "            time.sleep(1)  # Kurze Pause zwischen den Scrollvorgängen\n",
    "\n",
    "        time.sleep(2)\n",
    "\n",
    "        soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "        tm_table = soup.find('div', class_='row')\n",
    "        tm_rows = tm_table.find('div', class_='large-8 columns')\n",
    "        tm_history = tm_rows.find('tm-transfer-history', attrs={'player-id': spieler_id})\n",
    "\n",
    "        transfer_table = tm_history.find('div', class_='tm-transfer-history box')\n",
    "\n",
    "        transfer_data = []\n",
    "        for row in transfer_table.find_all('div'):\n",
    "            if row.find('div') is None or len(row.find_all('div')) < 6:\n",
    "                continue\n",
    "            divs = row.find_all('div')\n",
    "            if divs[0].text.strip() == \"Saison\":\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                old_club_nr = row.find('div', class_='tm-player-transfer-history-grid__old-club').find('a')['href']\n",
    "                abgebender_verein = old_club_nr.split('/')[4]\n",
    "                old_club_name = old_club_nr.split('/')[1]\n",
    "            except AttributeError:\n",
    "                abgebender_verein = None\n",
    "\n",
    "            try:\n",
    "                new_club_nr = row.find('div', class_='tm-player-transfer-history-grid__new-club').find('a')['href']\n",
    "                aufnehmender_verein = new_club_nr.split('/')[4]\n",
    "                new_club_name = new_club_nr.split('/')[1]\n",
    "            except AttributeError:\n",
    "                aufnehmender_verein = None\n",
    "\n",
    "            player_nr = url.split('/')[6]\n",
    "            saison = divs[0].text.strip()\n",
    "            datum = divs[1].text.strip()\n",
    "            mw = divs[4].text\n",
    "            ablöse = divs[5].text.strip()\n",
    "\n",
    "            transfer_data.append([player_nr, saison, datum, abgebender_verein, old_club_name, aufnehmender_verein, new_club_name, mw, ablöse])\n",
    "\n",
    "        # Schreibe die Daten für jeden Spieler in die gleiche CSV-Datei\n",
    "        writer.writerows(transfer_data)\n",
    "\n",
    "        print(old_club_nr.split('/')[1])\n",
    "        print(new_club_nr.split('/')[1])\n",
    "        print(f\"Daten für Spieler {spieler_id} wurden erfolgreich in transfer_data.csv gespeichert.\")\n",
    "\n",
    "driver.quit()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geopython310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
